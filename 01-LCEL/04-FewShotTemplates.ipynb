{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot Prompting 기법 가이드\n",
    "\n",
    "## 개요\n",
    "\n",
    "**Few-Shot Prompting**은 AI 언어 모델에게 소수의 예시를 제공하여 특정 작업의 성능을 향상시키는 프롬프트 엔지니어링 기법입니다. 이 기법은 모델이 원하는 출력 형식과 작업 패턴을 학습할 수 있도록 구체적인 예시를 통해 가이드를 제공합니다.\n",
    "\n",
    "### Few-Shot Prompting의 작동 원리\n",
    "\n",
    "Few-Shot Prompting은 다음과 같은 구조로 작동합니다:\n",
    "\n",
    "| 구성 요소 | 설명 | 예시 |\n",
    "|----------|------|------|\n",
    "| **Task Description** | 수행할 작업에 대한 설명 | \"다음 질문에 단계적으로 답변하세요\" |\n",
    "| **Examples** | 입력-출력 쌍의 예시들 | 질문 → 단계별 추론 과정 |\n",
    "| **Query** | 실제 처리할 새로운 입력 | 사용자의 실제 질문 |\n",
    "\n",
    "### 기대 효과\n",
    "\n",
    "- **정확성 향상**: 예시를 통한 명확한 출력 형식 지정\n",
    "- **일관성 확보**: 동일한 형태의 결과 생성\n",
    "- **복잡한 작업 처리**: 단순 지시보다 정교한 작업 수행 가능\n",
    "- **맥락 이해**: 작업의 의도와 목적에 대한 더 나은 이해\n",
    "\n",
    "## 주요 학습 내용\n",
    "\n",
    "### 1. FewShotPromptTemplate 기본 사용법\n",
    "- 예시 데이터 구성 방법\n",
    "- 프롬프트 템플릿 생성 및 활용\n",
    "- 체인 구성을 통한 실행\n",
    "\n",
    "### 2. Example Selector를 통한 동적 예시 선택\n",
    "- 유사성 기반 예시 자동 선택\n",
    "- 벡터 데이터베이스를 활용한 효율적인 예시 관리\n",
    "- 상황에 따른 최적 예시 적용\n",
    "\n",
    "### 3. FewShotChatMessagePromptTemplate\n",
    "- 대화형 Few-Shot 프롬프팅\n",
    "- 채팅 형태의 예시 구성\n",
    "- 다양한 작업 유형별 적용 방법\n",
    "\n",
    "### 기술적 요구사항\n",
    "\n",
    "| 항목 | 요구사항 |\n",
    "|------|---------|\n",
    "| **Python 패키지** | langchain-core, langchain-openai, langchain-chroma |\n",
    "| **API** | OpenAI API 또는 호환 가능한 LLM API |\n",
    "| **벡터 데이터베이스** | Chroma (예시 선택 기능용) |\n",
    "| **임베딩 모델** | text-embedding-3-small |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "LangChain-Tutorial\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"LangChain-Tutorial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국의 수도는 서울특별시(서울)입니다."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "# Create ChatOpenAI object\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    model_name=\"openai/gpt-4.1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=os.getenv(\"OPENROUTER_BASE_URL\"),\n",
    ")\n",
    "\n",
    "# Simple question to test LLM\n",
    "question = \"대한민국의 수도는 뭐야?\"\n",
    "\n",
    "# Execute query\n",
    "answer = llm.stream(question)\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Few-Shot에 사용할 예시 데이터 정의 (복잡한 추론 과정을 단계별로 보여주는 예시들)\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"스티브 잡스와 아인슈타인 중 누가 더 오래 살았나요?\",\n",
    "        \"answer\": \"\"\"이 질문에 추가 질문이 필요한가요: 예.\n",
    "추가 질문: 스티브 잡스는 몇 살에 사망했나요?\n",
    "중간 답변: 스티브 잡스는 56세에 사망했습니다.\n",
    "추가 질문: 아인슈타인은 몇 살에 사망했나요?\n",
    "중간 답변: 아인슈타인은 76세에 사망했습니다.\n",
    "최종 답변은: 아인슈타인\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"네이버의 창립자는 언제 태어났나요?\",\n",
    "        \"answer\": \"\"\"이 질문에 추가 질문이 필요한가요: 예.\n",
    "추가 질문: 네이버의 창립자는 누구인가요?\n",
    "중간 답변: 네이버는 이해진에 의해 창립되었습니다.\n",
    "추가 질문: 이해진은 언제 태어났나요?\n",
    "중간 답변: 이해진은 1967년 6월 22일에 태어났습니다.\n",
    "최종 답변은: 1967년 6월 22일\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"율곡 이이의 어머니가 태어난 해의 통치하던 왕은 누구인가요?\",\n",
    "        \"answer\": \"\"\"이 질문에 추가 질문이 필요한가요: 예.\n",
    "추가 질문: 율곡 이이의 어머니는 누구인가요?\n",
    "중간 답변: 율곡 이이의 어머니는 신사임당입니다.\n",
    "추가 질문: 신사임당은 언제 태어났나요?\n",
    "중간 답변: 신사임당은 1504년에 태어났습니다.\n",
    "추가 질문: 1504년에 조선을 통치한 왕은 누구인가요?\n",
    "중간 답변: 1504년에 조선을 통치한 왕은 연산군입니다.\n",
    "최종 답변은: 연산군\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"올드보이와 기생충의 감독이 같은 나라 출신인가요?\",\n",
    "        \"answer\": \"\"\"이 질문에 추가 질문이 필요한가요: 예.\n",
    "추가 질문: 올드보이의 감독은 누구인가요?\n",
    "중간 답변: 올드보이의 감독은 박찬욱입니다.\n",
    "추가 질문: 박찬욱은 어느 나라 출신인가요?\n",
    "중간 답변: 박찬욱은 대한민국 출신입니다.\n",
    "추가 질문: 기생충의 감독은 누구인가요?\n",
    "중간 답변: 기생충의 감독은 봉준호입니다.\n",
    "추가 질문: 봉준호는 어느 나라 출신인가요?\n",
    "중간 답변: 봉준호는 대한민국 출신입니다.\n",
    "최종 답변은: 예\n",
    "\"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "스티브 잡스와 아인슈타인 중 누가 더 오래 살았나요?\n",
      "Answer:\n",
      "이 질문에 추가 질문이 필요한가요: 예.\n",
      "추가 질문: 스티브 잡스는 몇 살에 사망했나요?\n",
      "중간 답변: 스티브 잡스는 56세에 사망했습니다.\n",
      "추가 질문: 아인슈타인은 몇 살에 사망했나요?\n",
      "중간 답변: 아인슈타인은 76세에 사망했습니다.\n",
      "최종 답변은: 아인슈타인\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 개별 예시를 위한 프롬프트 템플릿 생성\n",
    "example_prompt = PromptTemplate.from_template(\n",
    "    \"Question:\\n{question}\\nAnswer:\\n{answer}\"\n",
    ")\n",
    "\n",
    "# 첫 번째 예시로 템플릿 테스트\n",
    "print(example_prompt.format(**examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "스티브 잡스와 아인슈타인 중 누가 더 오래 살았나요?\n",
      "Answer:\n",
      "이 질문에 추가 질문이 필요한가요: 예.\n",
      "추가 질문: 스티브 잡스는 몇 살에 사망했나요?\n",
      "중간 답변: 스티브 잡스는 56세에 사망했습니다.\n",
      "추가 질문: 아인슈타인은 몇 살에 사망했나요?\n",
      "중간 답변: 아인슈타인은 76세에 사망했습니다.\n",
      "최종 답변은: 아인슈타인\n",
      "\n",
      "\n",
      "Question:\n",
      "네이버의 창립자는 언제 태어났나요?\n",
      "Answer:\n",
      "이 질문에 추가 질문이 필요한가요: 예.\n",
      "추가 질문: 네이버의 창립자는 누구인가요?\n",
      "중간 답변: 네이버는 이해진에 의해 창립되었습니다.\n",
      "추가 질문: 이해진은 언제 태어났나요?\n",
      "중간 답변: 이해진은 1967년 6월 22일에 태어났습니다.\n",
      "최종 답변은: 1967년 6월 22일\n",
      "\n",
      "\n",
      "Question:\n",
      "율곡 이이의 어머니가 태어난 해의 통치하던 왕은 누구인가요?\n",
      "Answer:\n",
      "이 질문에 추가 질문이 필요한가요: 예.\n",
      "추가 질문: 율곡 이이의 어머니는 누구인가요?\n",
      "중간 답변: 율곡 이이의 어머니는 신사임당입니다.\n",
      "추가 질문: 신사임당은 언제 태어났나요?\n",
      "중간 답변: 신사임당은 1504년에 태어났습니다.\n",
      "추가 질문: 1504년에 조선을 통치한 왕은 누구인가요?\n",
      "중간 답변: 1504년에 조선을 통치한 왕은 연산군입니다.\n",
      "최종 답변은: 연산군\n",
      "\n",
      "\n",
      "Question:\n",
      "올드보이와 기생충의 감독이 같은 나라 출신인가요?\n",
      "Answer:\n",
      "이 질문에 추가 질문이 필요한가요: 예.\n",
      "추가 질문: 올드보이의 감독은 누구인가요?\n",
      "중간 답변: 올드보이의 감독은 박찬욱입니다.\n",
      "추가 질문: 박찬욱은 어느 나라 출신인가요?\n",
      "중간 답변: 박찬욱은 대한민국 출신입니다.\n",
      "추가 질문: 기생충의 감독은 누구인가요?\n",
      "중간 답변: 기생충의 감독은 봉준호입니다.\n",
      "추가 질문: 봉준호는 어느 나라 출신인가요?\n",
      "중간 답변: 봉준호는 대한민국 출신입니다.\n",
      "최종 답변은: 예\n",
      "\n",
      "\n",
      "Question:\n",
      "Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "# FewShotPromptTemplate 생성 (모든 예시를 포함)\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,  # 사용할 예시 리스트\n",
    "    example_prompt=example_prompt,  # 개별 예시의 형식\n",
    "    suffix=\"Question:\\n{question}\\nAnswer:\",  # 실제 질문이 들어갈 부분\n",
    "    input_variables=[\"question\"],  # 입력 변수 정의\n",
    ")\n",
    "\n",
    "# 새로운 질문으로 프롬프트 생성\n",
    "question = \"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"\n",
    "final_prompt = prompt.format(question=question)\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 질문에 추가 질문이 필요한가요: 예.  \n",
      "추가 질문: Google이 창립된 연도는 언제인가요?  \n",
      "중간 답변: Google은 1998년에 창립되었습니다.  \n",
      "추가 질문: Bill Gates는 언제 태어났나요?  \n",
      "중간 답변: Bill Gates는 1955년 10월 28일에 태어났습니다.  \n",
      "추가 질문: 1998년에 Bill Gates의 나이는 몇 살이었나요?  \n",
      "중간 답변: 1998년 - 1955년 = 43년. Bill Gates는 1998년에 43세였습니다.  \n",
      "최종 답변은: 43세"
     ]
    }
   ],
   "source": [
    "# LLM으로 Few-Shot 프롬프트 실행\n",
    "answer = llm.stream(final_prompt)\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 질문에 추가 질문이 필요한가요: 예.  \n",
      "추가 질문: Google이 창립된 연도는 언제인가요?  \n",
      "중간 답변: Google은 1998년에 창립되었습니다.  \n",
      "추가 질문: Bill Gates는 언제 태어났나요?  \n",
      "중간 답변: Bill Gates는 1955년 10월 28일에 태어났습니다.  \n",
      "추가 질문: 1998년에 Bill Gates의 나이는 몇 살이었나요?  \n",
      "중간 답변: 1998년에서 1955년을 빼면 43이므로, Bill Gates는 1998년에 43세였습니다.  \n",
      "최종 답변은: 43세"
     ]
    }
   ],
   "source": [
    "# FewShotPromptTemplate으로 LangChain chain 구성\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Question:\\n{question}\\nAnswer:\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "# Chain 생성: 프롬프트 → LLM → 출력 파서\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Chain으로 질문 실행\n",
    "answer = chain.stream(\n",
    "    {\"question\": \"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"}\n",
    ")\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example Selector - 동적 예시 선택 시스템\n",
    "\n",
    "### 개요\n",
    "\n",
    "예시가 많아질수록 적절한 예시 선택이 중요해집니다. 모든 예시를 포함하면 프롬프트가 과도하게 길어지고, 관련 없는 예시는 AI의 성능을 저하시킬 수 있습니다.\n",
    "\n",
    "**Example Selector**는 현재 쿼리와 가장 관련성이 높은 예시들을 자동으로 선택하는 시스템입니다.\n",
    "\n",
    "### Example Selector의 작동 원리\n",
    "\n",
    "| 단계 | 설명 | 기술적 구현 |\n",
    "|------|------|-------------|\n",
    "| **1. 예시 저장** | 모든 예시를 벡터 데이터베이스에 저장 | 임베딩을 통한 벡터 변환 |\n",
    "| **2. 쿼리 분석** | 입력 쿼리를 벡터로 변환 | 동일한 임베딩 모델 사용 |\n",
    "| **3. 유사성 계산** | 코사인 유사도 등을 통한 거리 측정 | 벡터 간 수치적 비교 |\n",
    "| **4. 예시 선택** | 상위 k개의 가장 유사한 예시 선별 | 임계값 또는 개수 기준 |\n",
    "| **5. 프롬프트 구성** | 선별된 예시들로 최적 프롬프트 생성 | 동적 템플릿 구성 |\n",
    "\n",
    "### Example Selector 사용의 이점\n",
    "\n",
    "#### 성능 측면\n",
    "- **정확도 향상**: 맥락에 맞는 예시만 제공\n",
    "- **응답 일관성**: 유사한 작업에 대한 일관된 패턴 학습\n",
    "- **처리 효율성**: 불필요한 예시 제외로 빠른 처리\n",
    "\n",
    "#### 비용 및 관리 측면  \n",
    "- **토큰 최적화**: 관련 없는 예시 제외로 API 비용 절약\n",
    "- **확장성**: 새로운 예시 추가 시 자동 최적화\n",
    "- **유지보수**: 수동 예시 관리 부담 감소\n",
    "\n",
    "### 주요 Example Selector 유형\n",
    "\n",
    "| 유형 | 특징 | 적용 상황 |\n",
    "|------|------|----------|\n",
    "| **SemanticSimilarityExampleSelector** | 의미적 유사성 기반 | 일반적인 텍스트 작업 |\n",
    "| **MaxMarginalRelevanceExampleSelector** | 다양성과 관련성 균형 | 다양한 예시가 필요한 경우 |\n",
    "| **LengthBasedExampleSelector** | 길이 기반 선택 | 토큰 제한이 있는 환경 |\n",
    "\n",
    "- [API 문서 참조](https://api.python.langchain.com/en/latest/core/example_selectors.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.example_selectors import (\n",
    "    MaxMarginalRelevanceExampleSelector,\n",
    "    SemanticSimilarityExampleSelector,\n",
    ")\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# 벡터 데이터베이스 생성 (예시들을 벡터로 저장하기 위함)\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=os.getenv(\"EMBEDDING_BASE_URL\"),\n",
    ")\n",
    "\n",
    "chroma = Chroma(\"example_selector\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Your authentication token is not from a valid issuer.', 'type': 'invalid_request_error', 'code': 'invalid_issuer', 'param': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 유사성 기반 예시 선택기 생성\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m example_selector = \u001b[43mSemanticSimilarityExampleSelector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_examples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 선택 가능한 예시 목록\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 의미적 유사성을 측정하는 임베딩 모델\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 임베딩을 저장하고 유사성 검색을 수행하는 벡터스토어\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchroma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 선택할 예시의 개수\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# 테스트 질문\u001b[39;00m\n\u001b[32m     14\u001b[39m question = \u001b[33m\"\u001b[39m\u001b[33mGoogle이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\RAG_langchain\\.venv\\Lib\\site-packages\\langchain_core\\example_selectors\\semantic_similarity.py:171\u001b[39m, in \u001b[36mSemanticSimilarityExampleSelector.from_examples\u001b[39m\u001b[34m(cls, examples, embeddings, vectorstore_cls, k, input_keys, example_keys, vectorstore_kwargs, **vectorstore_cls_kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create k-shot example selector using example list and embeddings.\u001b[39;00m\n\u001b[32m    152\u001b[39m \n\u001b[32m    153\u001b[39m \u001b[33;03mReshuffles examples dynamically based on query similarity.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    168\u001b[39m \u001b[33;03m    The ExampleSelector instantiated, backed by a vector store.\u001b[39;00m\n\u001b[32m    169\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    170\u001b[39m string_examples = [\u001b[38;5;28mcls\u001b[39m._example_to_text(eg, input_keys) \u001b[38;5;28;01mfor\u001b[39;00m eg \u001b[38;5;129;01min\u001b[39;00m examples]\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m vectorstore = \u001b[43mvectorstore_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstring_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mvectorstore_cls_kwargs\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[32m    175\u001b[39m     vectorstore=vectorstore,\n\u001b[32m    176\u001b[39m     k=k,\n\u001b[32m   (...)\u001b[39m\u001b[32m    179\u001b[39m     vectorstore_kwargs=vectorstore_kwargs,\n\u001b[32m    180\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\RAG_langchain\\.venv\\Lib\\site-packages\\langchain_chroma\\vectorstores.py:1304\u001b[39m, in \u001b[36mChroma.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, host, port, headers, chroma_cloud_api_key, tenant, database, client_settings, client, collection_metadata, collection_configuration, ssl, **kwargs)\u001b[39m\n\u001b[32m   1296\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbatch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[32m   1298\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[32m   1299\u001b[39m         api=chroma_collection._client,\n\u001b[32m   1300\u001b[39m         ids=ids,\n\u001b[32m   1301\u001b[39m         metadatas=metadatas,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   1302\u001b[39m         documents=texts,\n\u001b[32m   1303\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m         \u001b[43mchroma_collection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1306\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1307\u001b[39m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1308\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1309\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1310\u001b[39m     chroma_collection.add_texts(texts=texts, metadatas=metadatas, ids=ids)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\RAG_langchain\\.venv\\Lib\\site-packages\\langchain_chroma\\vectorstores.py:606\u001b[39m, in \u001b[36mChroma.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m    604\u001b[39m texts = \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[32m    605\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m606\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[32m    608\u001b[39m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[32m    609\u001b[39m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[32m    610\u001b[39m     length_diff = \u001b[38;5;28mlen\u001b[39m(texts) - \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\RAG_langchain\\.venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:591\u001b[39m, in \u001b[36mOpenAIEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    588\u001b[39m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[32m    589\u001b[39m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[32m    590\u001b[39m engine = cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m.deployment)\n\u001b[32m--> \u001b[39m\u001b[32m591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\RAG_langchain\\.venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:479\u001b[39m, in \u001b[36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[39m\u001b[34m(self, texts, engine, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    477\u001b[39m batched_embeddings: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]] = []\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_kwargs\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    482\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    483\u001b[39m         response = response.model_dump()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\RAG_langchain\\.venv\\Lib\\site-packages\\openai\\resources\\embeddings.py:132\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    127\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    128\u001b[39m             ).tolist()\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\RAG_langchain\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\RAG_langchain\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': 'Your authentication token is not from a valid issuer.', 'type': 'invalid_request_error', 'code': 'invalid_issuer', 'param': None}}"
     ]
    }
   ],
   "source": [
    "# 유사성 기반 예시 선택기 생성\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # 선택 가능한 예시 목록\n",
    "    examples,\n",
    "    # 의미적 유사성을 측정하는 임베딩 모델\n",
    "    embeddings,\n",
    "    # 임베딩을 저장하고 유사성 검색을 수행하는 벡터스토어\n",
    "    chroma,\n",
    "    # 선택할 예시의 개수\n",
    "    k=1,\n",
    ")\n",
    "\n",
    "# 테스트 질문\n",
    "question = \"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"\n",
    "\n",
    "# 입력과 가장 유사한 예시 선택\n",
    "selected_examples = example_selector.select_examples({\"question\": question})\n",
    "\n",
    "print(f\"입력에 가장 유사한 예시:\\n{question}\\n\")\n",
    "for example in selected_examples:\n",
    "    print(f'question:\\n{example[\"question\"]}')\n",
    "    print(f'answer:\\n{example[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example_selector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Example Selector를 사용하는 FewShotPromptTemplate 생성\u001b[39;00m\n\u001b[32m      2\u001b[39m prompt = FewShotPromptTemplate(\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     example_selector=\u001b[43mexample_selector\u001b[49m,  \u001b[38;5;66;03m# 예시 리스트 대신 선택기 사용\u001b[39;00m\n\u001b[32m      4\u001b[39m     example_prompt=example_prompt,  \u001b[38;5;66;03m# 개별 예시의 형식\u001b[39;00m\n\u001b[32m      5\u001b[39m     suffix=\u001b[33m\"\u001b[39m\u001b[33mQuestion:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{question}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAnswer:\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# 실제 질문 부분\u001b[39;00m\n\u001b[32m      6\u001b[39m     input_variables=[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m],  \u001b[38;5;66;03m# 입력 변수\u001b[39;00m\n\u001b[32m      7\u001b[39m )\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 질문으로 프롬프트 생성 (자동으로 유사한 예시 선택됨)\u001b[39;00m\n\u001b[32m     10\u001b[39m question = \u001b[33m\"\u001b[39m\u001b[33mGoogle이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'example_selector' is not defined"
     ]
    }
   ],
   "source": [
    "# Example Selector를 사용하는 FewShotPromptTemplate 생성\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,  # 예시 리스트 대신 선택기 사용\n",
    "    example_prompt=example_prompt,  # 개별 예시의 형식\n",
    "    suffix=\"Question:\\n{question}\\nAnswer:\",  # 실제 질문 부분\n",
    "    input_variables=[\"question\"],  # 입력 변수\n",
    ")\n",
    "\n",
    "# 질문으로 프롬프트 생성 (자동으로 유사한 예시 선택됨)\n",
    "question = \"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"\n",
    "example_selector_prompt = prompt.format(question=question)\n",
    "print(example_selector_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Selector와 FewShotPromptTemplate 통합\n",
    "\n",
    "**Example Selector**를 **FewShotPromptTemplate**과 연결하여 동적 예시 선택 기능을 구현할 수 있습니다.\n",
    "\n",
    "#### 구현 방법\n",
    "\n",
    "**기본 방식 (정적 예시)**:\n",
    "```python\n",
    "FewShotPromptTemplate(\n",
    "    examples=examples,  # 모든 예시를 포함\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Question: {question}\\nAnswer:\",\n",
    "    input_variables=[\"question\"]\n",
    ")\n",
    "```\n",
    "\n",
    "**Example Selector 활용 (동적 예시)**:\n",
    "```python\n",
    "FewShotPromptTemplate(\n",
    "    example_selector=example_selector,  # 동적 선택기 사용\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Question: {question}\\nAnswer:\",\n",
    "    input_variables=[\"question\"]\n",
    ")\n",
    "```\n",
    "\n",
    "#### 주요 차이점\n",
    "\n",
    "| 특성 | 정적 예시 방식 | 동적 선택 방식 |\n",
    "|------|-------------|-------------|\n",
    "| **예시 선택** | 모든 예시 포함 | 관련성 기반 자동 선택 |\n",
    "| **프롬프트 길이** | 고정 (예시 개수에 비례) | 가변 (선택된 개수만큼) |\n",
    "| **성능** | 예시가 많으면 성능 저하 가능 | 최적화된 성능 |\n",
    "| **비용** | 높음 (많은 토큰 사용) | 효율적 (필요한 토큰만 사용) |\n",
    "\n",
    "이 방식을 통해 **질문이 바뀔 때마다 가장 적절한 예시들이 자동으로 선택**되어 프롬프트에 포함됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example_selector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Example Selector가 적용된 FewShotPromptTemplate으로 체인 생성\u001b[39;00m\n\u001b[32m      2\u001b[39m prompt = FewShotPromptTemplate(\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     example_selector=\u001b[43mexample_selector\u001b[49m,  \u001b[38;5;66;03m# 동적 예시 선택기\u001b[39;00m\n\u001b[32m      4\u001b[39m     example_prompt=example_prompt,  \u001b[38;5;66;03m# 개별 예시 형식\u001b[39;00m\n\u001b[32m      5\u001b[39m     suffix=\u001b[33m\"\u001b[39m\u001b[33mQuestion:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{question}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAnswer:\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# 질문 템플릿\u001b[39;00m\n\u001b[32m      6\u001b[39m     input_variables=[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      7\u001b[39m )\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 체인 생성 (프롬프트 → LLM)\u001b[39;00m\n\u001b[32m     10\u001b[39m chain = prompt | llm\n",
      "\u001b[31mNameError\u001b[39m: name 'example_selector' is not defined"
     ]
    }
   ],
   "source": [
    "# Example Selector가 적용된 FewShotPromptTemplate으로 체인 생성\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,  # 동적 예시 선택기\n",
    "    example_prompt=example_prompt,  # 개별 예시 형식\n",
    "    suffix=\"Question:\\n{question}\\nAnswer:\",  # 질문 템플릿\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "# 체인 생성 (프롬프트 → LLM)\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 질문에 추가 질문이 필요한가요: 예.  \n",
      "추가 질문: Google이 창립된 연도는 언제인가요?  \n",
      "중간 답변: Google은 1998년에 창립되었습니다.  \n",
      "추가 질문: Bill Gates는 언제 태어났나요?  \n",
      "중간 답변: Bill Gates는 1955년 10월 28일에 태어났습니다.  \n",
      "추가 질문: 1998년에 Bill Gates의 나이는 몇 살이었나요?  \n",
      "중간 답변: 1998년에서 1955년을 빼면 43이므로, Bill Gates는 1998년에 43세였습니다.  \n",
      "최종 답변은: 43세"
     ]
    }
   ],
   "source": [
    "# Example Selector를 사용한 체인 실행\n",
    "answer = chain.stream(\n",
    "    {\"question\": \"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"}\n",
    ")\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## FewShotChatMessagePromptTemplate - 대화형 Few-Shot\n",
    "\n",
    "### 개요\n",
    "\n",
    "**FewShotChatMessagePromptTemplate**은 대화형 인터페이스에 최적화된 Few-Shot 프롬프팅 기법입니다. 기존의 단순 텍스트 형태와 달리, Human과 AI 간의 대화 형태로 예시를 구성하여 더 자연스러운 상호작용을 가능하게 합니다.\n",
    "\n",
    "### 텍스트 기반 vs 대화 기반 Few-Shot 비교\n",
    "\n",
    "| 특성 | 텍스트 기반 | 대화 기반 |\n",
    "|------|-------------|----------|\n",
    "| **구조** | Input → Output | Human → AI |\n",
    "| **맥락 이해** | 제한적 | 대화 맥락 고려 |\n",
    "| **적용 분야** | 일반적인 변환 작업 | 챗봇, 상담 시스템 |\n",
    "| **톤/스타일** | 형식적 | 자연스러운 대화체 |\n",
    "\n",
    "### 대화형 Few-Shot의 장점\n",
    "\n",
    "#### 맥락적 일관성\n",
    "- **역할 인식**: AI가 대화 상대방으로서의 역할을 명확히 이해\n",
    "- **톤 유지**: 예시에서 보여준 말투와 스타일 지속\n",
    "- **대화 흐름**: 자연스러운 질문-답변 패턴 학습\n",
    "\n",
    "#### 특수 상황 대응\n",
    "- **전문가 역할**: 상담사, 교사, 기술 지원 등 특정 역할 설정\n",
    "- **감정적 대응**: 공감, 격려, 안내 등 상황에 맞는 반응\n",
    "- **다단계 대화**: 복잡한 문제 해결을 위한 연속적 대화\n",
    "\n",
    "### 활용 가능한 작업 유형\n",
    "\n",
    "| 작업 유형 | 설명 | 예시 상황 |\n",
    "|----------|------|----------|\n",
    "| **문서 작성** | 회의록, 보고서 등 구조화된 문서 | 업무 효율성 도구 |\n",
    "| **콘텐츠 요약** | 긴 텍스트의 핵심 내용 추출 | 정보 분석 도구 |\n",
    "| **텍스트 교정** | 문법, 표현, 스타일 개선 | 글쓰기 지원 도구 |\n",
    "| **창작 지원** | 아이디어 발전, 스토리텔링 | 콘텐츠 제작 도구 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대화형 Few-Shot에 사용할 다양한 작업 예시들\n",
    "examples = [\n",
    "    {\n",
    "        \"instruction\": \"당신은 회의록 작성 전문가 입니다. 주어진 정보를 바탕으로 회의록을 작성해 주세요\",\n",
    "        \"input\": \"2023년 12월 25일, XYZ 회사의 마케팅 전략 회의가 오후 3시에 시작되었다. 회의에는 마케팅 팀장인 김수진, 디지털 마케팅 담당자인 박지민, 소셜 미디어 관리자인 이준호가 참석했다. 회의의 주요 목적은 2024년 상반기 마케팅 전략을 수립하고, 새로운 소셜 미디어 캠페인에 대한 아이디어를 논의하는 것이었다. 팀장인 김수진은 최근 시장 동향에 대한 간략한 개요를 제공했으며, 이어서 각 팀원이 자신의 분야에서의 전략적 아이디어를 발표했다.\",\n",
    "        \"answer\": \"\"\"\n",
    "회의록: XYZ 회사 마케팅 전략 회의\n",
    "일시: 2023년 12월 25일\n",
    "장소: XYZ 회사 회의실\n",
    "참석자: 김수진 (마케팅 팀장), 박지민 (디지털 마케팅 담당자), 이준호 (소셜 미디어 관리자)\n",
    "\n",
    "1. 개회\n",
    "   - 회의는 김수진 팀장의 개회사로 시작됨.\n",
    "   - 회의의 목적은 2024년 상반기 마케팅 전략 수립 및 새로운 소셜 미디어 캠페인 아이디어 논의.\n",
    "\n",
    "2. 시장 동향 개요 (김수진)\n",
    "   - 김수진 팀장은 최근 시장 동향에 대한 분석을 제시.\n",
    "   - 소비자 행동 변화와 경쟁사 전략에 대한 통찰 공유.\n",
    "\n",
    "3. 디지털 마케팅 전략 (박지민)\n",
    "   - 박지민은 디지털 마케팅 전략에 대해 발표.\n",
    "   - 온라인 광고와 SEO 최적화 방안에 중점을 둠.\n",
    "\n",
    "4. 소셜 미디어 캠페인 (이준호)\n",
    "   - 이준호는 새로운 소셜 미디어 캠페인에 대한 아이디어를 제안.\n",
    "   - 인플루언서 마케팅과 콘텐츠 전략에 대한 계획을 설명함.\n",
    "\n",
    "5. 종합 논의\n",
    "   - 팀원들 간의 아이디어 공유 및 토론.\n",
    "   - 각 전략에 대한 예산 및 자원 배분에 대해 논의.\n",
    "\n",
    "6. 마무리\n",
    "   - 다음 회의 날짜 및 시간 확정.\n",
    "   - 회의록 정리 및 배포는 박지민 담당.\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"당신은 요약 전문가 입니다. 다음 주어진 정보를 바탕으로 내용을 요약해 주세요\",\n",
    "        \"input\": \"이 문서는 '지속 가능한 도시 개발을 위한 전략'에 대한 20페이지 분량의 보고서입니다. 보고서는 지속 가능한 도시 개발의 중요성, 현재 도시화의 문제점, 그리고 도시 개발을 지속 가능하게 만들기 위한 다양한 전략을 포괄적으로 다루고 있습니다. 이 보고서는 또한 성공적인 지속 가능한 도시 개발 사례를 여러 국가에서 소개하고, 이러한 사례들을 통해 얻은 교훈을 요약하고 있습니다.\",\n",
    "        \"answer\": \"\"\"\n",
    "문서 요약: 지속 가능한 도시 개발을 위한 전략 보고서\n",
    "\n",
    "- 중요성: 지속 가능한 도시 개발이 필수적인 이유와 그에 따른 사회적, 경제적, 환경적 이익을 강조.\n",
    "- 현 문제점: 현재의 도시화 과정에서 발생하는 주요 문제점들, 예를 들어 환경 오염, 자원 고갈, 불평등 증가 등을 분석.\n",
    "- 전략: 지속 가능한 도시 개발을 달성하기 위한 다양한 전략 제시. 이에는 친환경 건축, 대중교통 개선, 에너지 효율성 증대, 지역사회 참여 강화 등이 포함됨.\n",
    "- 사례 연구: 전 세계 여러 도시의 성공적인 지속 가능한 개발 사례를 소개. 예를 들어, 덴마크의 코펜하겐, 일본의 요코하마 등의 사례를 통해 실현 가능한 전략들을 설명.\n",
    "- 교훈: 이러한 사례들에서 얻은 주요 교훈을 요약. 강조된 교훈에는 다각적 접근의 중요성, 지역사회와의 협력, 장기적 계획의 필요성 등이 포함됨.\n",
    "\n",
    "이 보고서는 지속 가능한 도시 개발이 어떻게 현실적이고 효과적인 형태로 이루어질 수 있는지에 대한 심도 있는 분석을 제공합니다.\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"당신은 문장 교정 전문가 입니다. 다음 주어진 문장을 교정해 주세요\",\n",
    "        \"input\": \"우리 회사는 새로운 마케팅 전략을 도입하려고 한다. 이를 통해 고객과의 소통이 더 효과적이 될 것이다.\",\n",
    "        \"answer\": \"본 회사는 새로운 마케팅 전략을 도입함으로써, 고객과의 소통을 보다 효과적으로 개선할 수 있을 것으로 기대된다.\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Your authentication token is not from a valid issuer.', 'type': 'invalid_request_error', 'code': 'invalid_issuer', 'param': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     19\u001b[39m example_prompt = ChatPromptTemplate.from_messages(\n\u001b[32m     20\u001b[39m     [\n\u001b[32m     21\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33mhuman\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{instruction}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[33m\"\u001b[39m),  \u001b[38;5;66;03m# 사용자의 지시사항과 입력\u001b[39;00m\n\u001b[32m     22\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33mai\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{answer}\u001b[39;00m\u001b[33m\"\u001b[39m),  \u001b[38;5;66;03m# AI의 응답\u001b[39;00m\n\u001b[32m     23\u001b[39m     ]\n\u001b[32m     24\u001b[39m )\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# 유사성 기반 예시 선택기 생성 (instruction 기준으로 유사성 판단)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m example_selector = \u001b[43mSemanticSimilarityExampleSelector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_examples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 선택 가능한 예시 목록\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 의미적 유사성을 측정하는 임베딩 모델\u001b[39;49;00m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 임베딩을 저장하고 유사성 검색을 수행하는 벡터스토어\u001b[39;49;00m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchroma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 선택할 예시의 개수\u001b[39;49;00m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 유사성 판단 기준 (instruction 필드 기준)\u001b[39;49;00m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstruction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# FewShotChatMessagePromptTemplate 생성\u001b[39;00m\n\u001b[32m     41\u001b[39m few_shot_prompt = FewShotChatMessagePromptTemplate(\n\u001b[32m     42\u001b[39m     example_selector=example_selector,  \u001b[38;5;66;03m# 동적 예시 선택기\u001b[39;00m\n\u001b[32m     43\u001b[39m     example_prompt=example_prompt,  \u001b[38;5;66;03m# 개별 예시 형식\u001b[39;00m\n\u001b[32m     44\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\RAG_langchain\\.venv\\Lib\\site-packages\\langchain_core\\example_selectors\\semantic_similarity.py:171\u001b[39m, in \u001b[36mSemanticSimilarityExampleSelector.from_examples\u001b[39m\u001b[34m(cls, examples, embeddings, vectorstore_cls, k, input_keys, example_keys, vectorstore_kwargs, **vectorstore_cls_kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create k-shot example selector using example list and embeddings.\u001b[39;00m\n\u001b[32m    152\u001b[39m \n\u001b[32m    153\u001b[39m \u001b[33;03mReshuffles examples dynamically based on query similarity.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    168\u001b[39m \u001b[33;03m    The ExampleSelector instantiated, backed by a vector store.\u001b[39;00m\n\u001b[32m    169\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    170\u001b[39m string_examples = [\u001b[38;5;28mcls\u001b[39m._example_to_text(eg, input_keys) \u001b[38;5;28;01mfor\u001b[39;00m eg \u001b[38;5;129;01min\u001b[39;00m examples]\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m vectorstore = \u001b[43mvectorstore_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstring_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mvectorstore_cls_kwargs\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[32m    175\u001b[39m     vectorstore=vectorstore,\n\u001b[32m    176\u001b[39m     k=k,\n\u001b[32m   (...)\u001b[39m\u001b[32m    179\u001b[39m     vectorstore_kwargs=vectorstore_kwargs,\n\u001b[32m    180\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\RAG_langchain\\.venv\\Lib\\site-packages\\langchain_chroma\\vectorstores.py:1304\u001b[39m, in \u001b[36mChroma.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, host, port, headers, chroma_cloud_api_key, tenant, database, client_settings, client, collection_metadata, collection_configuration, ssl, **kwargs)\u001b[39m\n\u001b[32m   1296\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbatch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[32m   1298\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[32m   1299\u001b[39m         api=chroma_collection._client,\n\u001b[32m   1300\u001b[39m         ids=ids,\n\u001b[32m   1301\u001b[39m         metadatas=metadatas,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   1302\u001b[39m         documents=texts,\n\u001b[32m   1303\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m         \u001b[43mchroma_collection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1306\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1307\u001b[39m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1308\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1309\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1310\u001b[39m     chroma_collection.add_texts(texts=texts, metadatas=metadatas, ids=ids)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\RAG_langchain\\.venv\\Lib\\site-packages\\langchain_chroma\\vectorstores.py:606\u001b[39m, in \u001b[36mChroma.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m    604\u001b[39m texts = \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[32m    605\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m606\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[32m    608\u001b[39m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[32m    609\u001b[39m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[32m    610\u001b[39m     length_diff = \u001b[38;5;28mlen\u001b[39m(texts) - \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\RAG_langchain\\.venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:591\u001b[39m, in \u001b[36mOpenAIEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    588\u001b[39m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[32m    589\u001b[39m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[32m    590\u001b[39m engine = cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m.deployment)\n\u001b[32m--> \u001b[39m\u001b[32m591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\RAG_langchain\\.venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:479\u001b[39m, in \u001b[36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[39m\u001b[34m(self, texts, engine, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    477\u001b[39m batched_embeddings: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]] = []\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_kwargs\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    482\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    483\u001b[39m         response = response.model_dump()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\RAG_langchain\\.venv\\Lib\\site-packages\\openai\\resources\\embeddings.py:132\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    127\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    128\u001b[39m             ).tolist()\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\RAG_langchain\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\RAG_langchain\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': 'Your authentication token is not from a valid issuer.', 'type': 'invalid_request_error', 'code': 'invalid_issuer', 'param': None}}"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_core.example_selectors import (\n",
    "    SemanticSimilarityExampleSelector,\n",
    ")\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# 채팅용 벡터 데이터베이스 생성\n",
    "chroma = Chroma(\n",
    "    \"fewshot_chat\",\n",
    "    OpenAIEmbeddings(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "        base_url=os.getenv(\"EMBEDDING_BASE_URL\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 개별 예시를 위한 채팅 프롬프트 템플릿 (Human-AI 대화 형태)\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{instruction}:\\n{input}\"),  # 사용자의 지시사항과 입력\n",
    "        (\"ai\", \"{answer}\"),  # AI의 응답\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 유사성 기반 예시 선택기 생성 (instruction 기준으로 유사성 판단)\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # 선택 가능한 예시 목록\n",
    "    examples,\n",
    "    # 의미적 유사성을 측정하는 임베딩 모델\n",
    "    embeddings,\n",
    "    # 임베딩을 저장하고 유사성 검색을 수행하는 벡터스토어\n",
    "    chroma,\n",
    "    # 선택할 예시의 개수\n",
    "    k=1,\n",
    "    # 유사성 판단 기준 (instruction 필드 기준)\n",
    "    input_keys=[\"instruction\"],\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 생성\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_selector=example_selector,  # 동적 예시 선택기\n",
    "    example_prompt=example_prompt,  # 개별 예시 형식\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Selector를 활용한 동적 예시 선택\n",
    "\n",
    "**FewShotChatMessagePromptTemplate**과 **Example Selector**를 결합하면 사용자의 질문에 따라 가장 관련성 높은 예시가 자동으로 선택되어 프롬프트에 포함됩니다.\n",
    "\n",
    "#### 작동 과정\n",
    "\n",
    "| 단계 | 작업 내용 | 기술적 세부사항 |\n",
    "|------|----------|---------------|\n",
    "| **1. 입력 분석** | 사용자 질문의 `instruction` 필드 분석 | 임베딩 모델을 통한 벡터 변환 |\n",
    "| **2. 유사성 측정** | 저장된 예시들과의 의미적 유사성 계산 | 코사인 유사도 또는 유클리드 거리 |\n",
    "| **3. 예시 선택** | k개의 가장 유사한 예시 선별 | 임계값 기반 필터링 |\n",
    "| **4. 프롬프트 구성** | 선택된 예시를 포함한 최적 프롬프트 생성 | 동적 템플릿 렌더링 |\n",
    "| **5. 응답 생성** | 맥락에 맞는 정확한 답변 생성 | LLM을 통한 추론 실행 |\n",
    "\n",
    "#### 설정 매개변수\n",
    "\n",
    "```python\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples=examples,           # 선택 가능한 예시 목록\n",
    "    embeddings=embeddings,       # 임베딩 모델\n",
    "    vectorstore=vectorstore,     # 벡터 저장소\n",
    "    k=1,                        # 선택할 예시 개수\n",
    "    input_keys=[\"instruction\"]   # 유사성 판단 기준 필드\n",
    ")\n",
    "```\n",
    "\n",
    "이 방식을 통해 **맥락에 적합한 정확한 답변**을 효율적으로 생성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example_selector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      2\u001b[39m question = {\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minstruction\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m회의록을 작성해 주세요\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m2023년 12월 26일, ABC 기술 회사의 제품 개발 팀은 새로운 모바일 애플리케이션 프로젝트에 대한 주간 진행 상황 회의를 가졌다. 이 회의에는 프로젝트 매니저인 최현수, 주요 개발자인 황지연, UI/UX 디자이너인 김태영이 참석했다. 회의의 주요 목적은 프로젝트의 현재 진행 상황을 검토하고, 다가오는 마일스톤에 대한 계획을 수립하는 것이었다. 각 팀원은 자신의 작업 영역에 대한 업데이트를 제공했고, 팀은 다음 주까지의 목표를 설정했다.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m }\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# instruction을 기준으로 가장 유사한 예시 선택\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mexample_selector\u001b[49m.select_examples(question)\n",
      "\u001b[31mNameError\u001b[39m: name 'example_selector' is not defined"
     ]
    }
   ],
   "source": [
    "# 회의록 작성 관련 질문으로 유사한 예시 선택 테스트\n",
    "question = {\n",
    "    \"instruction\": \"회의록을 작성해 주세요\",\n",
    "    \"input\": \"2023년 12월 26일, ABC 기술 회사의 제품 개발 팀은 새로운 모바일 애플리케이션 프로젝트에 대한 주간 진행 상황 회의를 가졌다. 이 회의에는 프로젝트 매니저인 최현수, 주요 개발자인 황지연, UI/UX 디자이너인 김태영이 참석했다. 회의의 주요 목적은 프로젝트의 현재 진행 상황을 검토하고, 다가오는 마일스톤에 대한 계획을 수립하는 것이었다. 각 팀원은 자신의 작업 영역에 대한 업데이트를 제공했고, 팀은 다음 주까지의 목표를 설정했다.\",\n",
    "}\n",
    "\n",
    "# instruction을 기준으로 가장 유사한 예시 선택\n",
    "example_selector.select_examples(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'few_shot_prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 최종 채팅 프롬프트 구성: 시스템 메시지 + 예시 + 사용자 질문\u001b[39;00m\n\u001b[32m      2\u001b[39m final_prompt = ChatPromptTemplate.from_messages(\n\u001b[32m      3\u001b[39m     [\n\u001b[32m      4\u001b[39m         (\n\u001b[32m      5\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou are a helpful assistant.\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# 시스템 역할 정의\u001b[39;00m\n\u001b[32m      7\u001b[39m         ),\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m         \u001b[43mfew_shot_prompt\u001b[49m,  \u001b[38;5;66;03m# 선택된 예시가 자동으로 포함됨\u001b[39;00m\n\u001b[32m      9\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33mhuman\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{instruction}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[33m\"\u001b[39m),  \u001b[38;5;66;03m# 실제 사용자 질문\u001b[39;00m\n\u001b[32m     10\u001b[39m     ]\n\u001b[32m     11\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'few_shot_prompt' is not defined"
     ]
    }
   ],
   "source": [
    "# 최종 채팅 프롬프트 구성: 시스템 메시지 + 예시 + 사용자 질문\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant.\",  # 시스템 역할 정의\n",
    "        ),\n",
    "        few_shot_prompt,  # 선택된 예시가 자동으로 포함됨\n",
    "        (\"human\", \"{instruction}\\n{input}\"),  # 실제 사용자 질문\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대화형 Few-Shot Chain 생성 및 실행\n",
    "chain = final_prompt | llm\n",
    "\n",
    "# 회의록 작성 요청으로 chain 실행\n",
    "answer = chain.stream(question)\n",
    "stream_response(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
