{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "z52x0tivhe",
   "metadata": {},
   "source": [
    "# OpenAI ChatGPT API와 LangChain 활용 가이드\n",
    "\n",
    "## 개요\n",
    "\n",
    "이 튜토리얼은 OpenAI 호환 Chat API 를 LangChain 과 함께 사용하는 방법을 설명한다. 실행 환경 구성, 기본 호출, 응답 구조, 스트리밍, 멀티모달, 프롬프트 설계를 단계별로 다룬다. 본 문서에서는 OpenRouter 를 통해 모델을 호출한다.\n",
    "\n",
    "### 학습 목표\n",
    "\n",
    "- **LangChain** 과 **LCEL(LangChain Expression Language)** 기본 개념 이해\n",
    "- **ChatOpenAI** 클래스 초기화와 호출 흐름 이해\n",
    "- **모델/파라미터 선택 기준** 이해\n",
    "- **스트리밍, LogProb, 멀티모달** 사용법 습득\n",
    "- **프롬프트 설계** 기본 원칙 정리\n",
    "\n",
    "### 목차\n",
    "\n",
    "1. 환경 설정과 LangSmith 연동\n",
    "2. LangChain 과 LCEL 핵심 개념\n",
    "3. ChatOpenAI 기본 사용법\n",
    "4. 응답 구조 이해\n",
    "5. 고급 기능: LogProb, 스트리밍, 멀티모달\n",
    "6. 프롬프트 엔지니어링\n",
    "---\n",
    "\n",
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3bf28f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93ac45ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "LangChain-Tutorial\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# .env 파일에 LANGCHAIN_API_KEY를 입력합니다.\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"LangChain-Tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4xwrsfd5d6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## LangChain 과 LCEL 기본 개념\n",
    "\n",
    "### LangChain 이란?\n",
    "\n",
    "**LangChain** 은 Large Language Model(LLM) 기반 애플리케이션 개발을 위한 **통합 프레임워크** 이다.\n",
    "\n",
    "#### LangChain 의 핵심 가치\n",
    "\n",
    "- **표준화**: 다양한 LLM 을 동일한 인터페이스로 사용\n",
    "- **구성요소화**: 프롬프트, 모델, 파서 등 모듈로 재사용\n",
    "- **확장성**: 필요에 따라 컴포넌트 교체/추가 용이\n",
    "- **추적성**: LangSmith 등과 연동하여 실행을 기록\n",
    "\n",
    "### LCEL (LangChain Expression Language)\n",
    "\n",
    "**LCEL** 은 LangChain 컴포넌트들을 **체인처럼 연결** 하는 표현식이다.\n",
    "\n",
    "#### LCEL 의 특징\n",
    "\n",
    "![](images/lcel.png)\n",
    "\n",
    "```python\n",
    "# LCEL 방식 - 간결하고 명확\n",
    "chain = prompt | llm | output_parser\n",
    "result = chain.invoke({\"input\": input_text})\n",
    "```\n",
    "\n",
    "#### LCEL 의 장점\n",
    "\n",
    "- **가독성**: 처리 흐름을 한눈에 파악 가능\n",
    "- **최적화 실행**: 내부적으로 병렬화 및 스트리밍 지원\n",
    "- **견고성**: 예외 처리와 재시도 전략을 손쉽게 적용\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2550920c-09d8-48b3-be2f-b36362c37989",
   "metadata": {},
   "source": [
    "## ChatOpenAI - OpenAI 호환 인터페이스\n",
    "\n",
    "**ChatOpenAI** 는 OpenAI 호환 Chat API 를 LangChain 에서 사용할 수 있도록 제공하는 **통합 인터페이스** 이다. 본 튜토리얼에서는 OpenRouter 를 사용한다.\n",
    "\n",
    "### 주요 설정 옵션\n",
    "\n",
    "| 파라미터 | 목적 | 권장값(예시) |\n",
    "| :-- | :-- | :-- |\n",
    "| temperature | 출력 다양성 조절 | 0.1 |\n",
    "| model_name | 사용할 모델 | openai/gpt-4.1 |\n",
    "| api_key | 인증 키 | os.getenv('OPENROUTER_API_KEY') |\n",
    "| base_url | API 엔드포인트 | os.getenv('OPENROUTER_BASE_URL') |\n",
    "| max_tokens | 최대 출력 길이 | 필요 시 지정 |\n",
    "\n",
    "#### temperature (창의성 조절)\n",
    "```python\n",
    "temperature=0.1  # 일관되고 정확한 답변 (사실 질문에 적합)\n",
    "temperature=0.8  # 창의적이고 다양한 답변 (창작 활동에 적합)\n",
    "```\n",
    "- **범위**: 0.0 ~ 2.0\n",
    "- **낮은 값 (0.0~0.3)**: 정확하고 일관된 답변\n",
    "- **중간 값 (0.4~0.7)**: 일반적인 대화에 적합\n",
    "- **높은 값 (0.8~2.0)**: 다양한 표현 생성\n",
    "\n",
    "#### max_tokens (최대 출력 길이)\n",
    "```python\n",
    "max_tokens=2048\n",
    "```\n",
    "- **의미**: 생성할 토큰의 상한\n",
    "- **참고**: 과도한 설정은 비용에 영향을 준다\n",
    "\n",
    "#### model_name (사용할 모델)\n",
    "- **GPT-4.1**: 고성능 모델, 복잡한 추론과 멀티모달 지원\n",
    "- **GPT-4.1-mini**: 성능과 비용의 균형\n",
    "- **GPT-4.1-nano**: 경량 작업에 적합\n",
    "\n",
    "### OpenAI 모델 비교표\n",
    "\n",
    "| 모델 계열       | 모델명 (API Name) | 입력       | 컨텍스트 윈도우  | 최대 출력 토큰 | 지식 마감일 (Cutoff) | 가격 (1M토큰당)                  |\n",
    "| :---------- | :------------- | :------- | :-------- | :------- | :-------------- | :------------------------------ |\n",
    "| **GPT-5**   | `gpt-5`        | 텍스트, 이미지 | 400,000   | 128,000  | 2024년 9월 30일    | **입력:** $1.25<br>**출력:** $10.00 |\n",
    "|             | `gpt-5-mini`   | 텍스트, 이미지 | 400,000   | 128,000  | 2024년 5월 31일    | **입력:** $0.25<br>**출력:** $2.00  |\n",
    "|             | `gpt-5-nano`   | 텍스트, 이미지 | 400,000   | 128,000  | 2024년 5월 31일    | **입력:** $0.05<br>**출력:** $0.40  |\n",
    "| **GPT-4.1** | `gpt-4.1`      | 텍스트, 이미지 | 1,047,576 | 32,768   | 2024년 6월 1일     | **입력:** $2.00<br>**출력:** $8.00  |\n",
    "|             | `gpt-4.1-mini` | 텍스트, 이미지 | 1,047,576 | 32,768   | 2024년 6월 1일     | **입력:** $0.40<br>**출력:** $1.60  |\n",
    "|             | `gpt-4.1-nano` | 텍스트, 이미지 | 1,047,576 | 32,768   | 2024년 6월 1일     | **입력:** $0.10<br>**출력:** $0.40  |\n",
    "| **GPT-4o**  | `gpt-4o`       | 텍스트, 이미지 | 128,000   | 16,384   | 2023년 10월 1일    | **입력:** $2.50<br>**출력:** $10.00 |\n",
    "|             | `gpt-4o-mini`  | 텍스트, 이미지 | 128,000   | 16,384   | 2023년 10월 1일    | **입력:** $0.15<br>**출력:** $0.60  |\n",
    "\n",
    "![OpenAI Models Comparison](./images/gpt-models3-202508.png)\n",
    "\n",
    "### 모델 선택 가이드\n",
    "\n",
    "- **정확성 우선**: `gpt-4.1`\n",
    "- **균형 선택**: `gpt-4.1-mini`\n",
    "- **비용 절약**: `gpt-4.1-nano`\n",
    "\n",
    "> **참고 링크**: [OpenAI 공식 모델 문서](https://platform.openai.com/docs/models)\n",
    "\n",
    "### 기본 사용법\n",
    "\n",
    "이제 ChatOpenAI 를 사용해 기본 호출을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fc161c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[답변]: content='대한민국의 수도는 서울특별시(서울)입니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 16, 'total_tokens': 30, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_433e8c8649', 'id': 'chatcmpl-CkOr5vNIElH4aZq4QDPhg2PXxWRZI', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--cd480a48-9775-423c-9d73-455a76bf343d-0' usage_metadata={'input_tokens': 16, 'output_tokens': 14, 'total_tokens': 30, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "# ChatOpenAI 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0) - 낮을수록 일관된 답변\n",
    "    model_name=\"openai/gpt-4.1\",  # 사용할 모델명 (OpenRouter)\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),  # OpenRouter API 키\n",
    "    base_url=os.getenv(\"OPENROUTER_BASE_URL\"),  # OpenRouter API URL\n",
    ")\n",
    "\n",
    "# 사용자 질의내용 정의\n",
    "question = \"대한민국의 수도는 어디인가요?\"\n",
    "\n",
    "# LLM에 질의하고 결과 출력\n",
    "print(f\"[답변]: {llm.invoke(question)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ef2647",
   "metadata": {},
   "source": [
    "### AIMessage 객체\n",
    "\n",
    "ChatOpenAI 의 응답은 단순 텍스트가 아닌 **AIMessage 객체** 로 반환된다. 객체에는 본문과 메타데이터가 포함된다.\n",
    "\n",
    "#### AIMessage 의 구성 요소\n",
    "\n",
    "- **content**: 실제 AI 가 생성한 텍스트 답변\n",
    "- **response_metadata**: 토큰 사용량, 모델 정보, 처리 시간 등 메타데이터\n",
    "- **기타 정보**: 메시지 ID, 타입 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2af58a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 질의내용 정의\n",
    "question = \"대한민국의 수도는 어디인가요?\"\n",
    "\n",
    "# LLM에 질의하고 응답 객체를 변수에 저장\n",
    "response = llm.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24ecdeb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='대한민국의 수도는 서울특별시(서울)입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 16, 'total_tokens': 30, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_433e8c8649', 'id': 'chatcmpl-CkOr6gyncvE5UBgbMZp4g5FIycOl1', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--53b4980c-419a-4bcc-847a-47b2d0f1ff4f-0', usage_metadata={'input_tokens': 16, 'output_tokens': 14, 'total_tokens': 30, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 응답 객체 확인 (AIMessage 형태)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ffd49c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 서울특별시(서울)입니다.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 응답 내용만 텍스트로 추출\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4df69214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 14,\n",
       "  'prompt_tokens': 16,\n",
       "  'total_tokens': 30,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-4.1-2025-04-14',\n",
       " 'system_fingerprint': 'fp_433e8c8649',\n",
       " 'id': 'chatcmpl-CkOr6gyncvE5UBgbMZp4g5FIycOl1',\n",
       " 'service_tier': 'default',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 응답 메타데이터 확인 (토큰 사용량, 모델 정보 등)\n",
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c4a51a",
   "metadata": {},
   "source": [
    "### LogProb - 토큰 선택 확률 정보\n",
    "\n",
    "**LogProb(로그 확률)** 은 모델이 각 토큰을 선택할 때의 상대적 확률 정보를 제공한다. 답변의 신뢰도 판단 및 품질 관리에 활용할 수 있다.\n",
    "\n",
    "#### 활용 예\n",
    "\n",
    "- **답변 신뢰도 평가**: 낮은 확률 구간을 감지해 후속 확인 수행\n",
    "- **품질 관리**: 불확실한 응답을 필터링하거나 재생성\n",
    "- **모델 분석**: 토큰 수준의 선택 경향 파악\n",
    "- **후처리**: 확률 기준으로 후보 답변 비교\n",
    "\n",
    "#### 해석 방법 (경험칙)\n",
    "\n",
    "- **높은 확률 (-0.1 ~ 0.0)**: 높은 확신\n",
    "- **중간 확률 (-2.0 ~ -0.1)**: 보통 수준의 확신\n",
    "- **낮은 확률 (-5.0 이하)**: 낮은 확신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fe733438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogProb 기능이 활성화된 ChatOpenAI 객체 생성\n",
    "import os\n",
    "\n",
    "llm_with_logprob = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 출력 토큰 수\n",
    "    model_name=\"openai/gpt-4.1\",  # 사용할 모델명 (OpenRouter)\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),  # OpenRouter API 키\n",
    "    base_url=os.getenv(\"OPENROUTER_BASE_URL\"),  # OpenRouter API URL\n",
    ").bind(\n",
    "    logprobs=True,\n",
    "    top_logprobs=5,  # 상위 3개 토큰 확률 정보 포함\n",
    ")  # 토큰별 확률 정보 활성화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8ae2d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 질의내용 정의\n",
    "question = \"대한민국의 수도는 어디인가요?\"\n",
    "\n",
    "# LogProb가 활성화된 LLM으로 질의\n",
    "response = llm_with_logprob.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e6b0b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogProb 정보가 포함된 메타데이터 확인\n",
    "response_metadata = response.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "755e1f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token': '대한',\n",
       " 'bytes': [235, 140, 128, 237, 149, 156],\n",
       " 'logprob': -3.128163257315464e-07,\n",
       " 'top_logprobs': [{'token': '대한',\n",
       "   'bytes': [235, 140, 128, 237, 149, 156],\n",
       "   'logprob': -3.128163257315464e-07},\n",
       "  {'token': ' 대한민국',\n",
       "   'bytes': [32, 235, 140, 128, 237, 149, 156, 235, 175, 188, 234, 181, 173],\n",
       "   'logprob': -15.375},\n",
       "  {'token': '네', 'bytes': [235, 132, 164], 'logprob': -18.375},\n",
       "  {'token': '\"', 'bytes': [34], 'logprob': -20.125},\n",
       "  {'token': '대', 'bytes': [235, 140, 128], 'logprob': -20.375}]}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_metadata[\"logprobs\"]['content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "166979c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token': '대한', 'bytes': [235, 140, 128, 237, 149, 156], 'logprob': -3.128163257315464e-07, 'top_logprobs': [{'token': '대한', 'bytes': [235, 140, 128, 237, 149, 156], 'logprob': -3.128163257315464e-07}, {'token': ' 대한민국', 'bytes': [32, 235, 140, 128, 237, 149, 156, 235, 175, 188, 234, 181, 173], 'logprob': -15.375}, {'token': '네', 'bytes': [235, 132, 164], 'logprob': -18.375}, {'token': '\"', 'bytes': [34], 'logprob': -20.125}, {'token': '대', 'bytes': [235, 140, 128], 'logprob': -20.375}]}\n",
      "{'token': '민국', 'bytes': [235, 175, 188, 234, 181, 173], 'logprob': 0.0, 'top_logprobs': [{'token': '민국', 'bytes': [235, 175, 188, 234, 181, 173], 'logprob': 0.0}, {'token': '민', 'bytes': [235, 175, 188], 'logprob': -18.875}, {'token': '미', 'bytes': [235, 175, 184], 'logprob': -20.125}, {'token': ' 대한민국', 'bytes': [32, 235, 140, 128, 237, 149, 156, 235, 175, 188, 234, 181, 173], 'logprob': -21.875}, {'token': '한국', 'bytes': [237, 149, 156, 234, 181, 173], 'logprob': -22.625}]}\n",
      "{'token': '의', 'bytes': [236, 157, 152], 'logprob': -0.0002613358374219388, 'top_logprobs': [{'token': '의', 'bytes': [236, 157, 152], 'logprob': -0.0002613358374219388}, {'token': '(', 'bytes': [40], 'logprob': -8.250261306762695}, {'token': '(K', 'bytes': [40, 75], 'logprob': -16.750261306762695}, {'token': 'の', 'bytes': [227, 129, 174], 'logprob': -18.750261306762695}, {'token': ',', 'bytes': [44], 'logprob': -21.375261306762695}]}\n",
      "{'token': ' 수도', 'bytes': [32, 236, 136, 152, 235, 143, 132], 'logprob': -1.9361264946837764e-07, 'top_logprobs': [{'token': ' 수도', 'bytes': [32, 236, 136, 152, 235, 143, 132], 'logprob': -1.9361264946837764e-07}, {'token': ' 수', 'bytes': [32, 236, 136, 152], 'logprob': -15.75}, {'token': ' **', 'bytes': [32, 42, 42], 'logprob': -18.125}, {'token': '\\xa0', 'bytes': [194, 160], 'logprob': -18.5}, {'token': ' 공식', 'bytes': [32, 234, 179, 181, 236, 139, 157], 'logprob': -19.0}]}\n",
      "{'token': '는', 'bytes': [235, 138, 148], 'logprob': 0.0, 'top_logprobs': [{'token': '는', 'bytes': [235, 138, 148], 'logprob': 0.0}, {'token': 'は', 'bytes': [227, 129, 175], 'logprob': -20.375}, {'token': '은', 'bytes': [236, 157, 128], 'logprob': -22.125}, {'token': ' 는', 'bytes': [32, 235, 138, 148], 'logprob': -22.875}, {'token': '(', 'bytes': [40], 'logprob': -23.0}]}\n",
      "{'token': ' 서울', 'bytes': [32, 236, 132, 156, 236, 154, 184], 'logprob': -0.6948215961456299, 'top_logprobs': [{'token': ' **', 'bytes': [32, 42, 42], 'logprob': -0.6948215961456299}, {'token': ' 서울', 'bytes': [32, 236, 132, 156, 236, 154, 184], 'logprob': -0.6948215961456299}, {'token': ' \"', 'bytes': [32, 34], 'logprob': -6.444821357727051}, {'token': \" '\", 'bytes': [32, 39], 'logprob': -9.69482135772705}, {'token': ' \"**', 'bytes': [32, 34, 42, 42], 'logprob': -11.19482135772705}]}\n",
      "{'token': '특', 'bytes': [237, 138, 185], 'logprob': -0.10137175768613815, 'top_logprobs': [{'token': '특', 'bytes': [237, 138, 185], 'logprob': -0.10137175768613815}, {'token': '입니다', 'bytes': [236, 158, 133, 235, 139, 136, 235, 139, 164], 'logprob': -2.3513717651367188}, {'token': '(', 'bytes': [40], 'logprob': -6.851371765136719}, {'token': ' 특별', 'bytes': [32, 237, 138, 185, 235, 179, 132], 'logprob': -9.226371765136719}, {'token': ' Special', 'bytes': [32, 83, 112, 101, 99, 105, 97, 108], 'logprob': -12.601371765136719}]}\n",
      "{'token': '별', 'bytes': [235, 179, 132], 'logprob': 0.0, 'top_logprobs': [{'token': '별', 'bytes': [235, 179, 132], 'logprob': 0.0}, {'token': '別', 'bytes': [229, 136, 165], 'logprob': -18.375}, {'token': ' 별', 'bytes': [32, 235, 179, 132], 'logprob': -19.0}, {'token': '别', 'bytes': [229, 136, 171], 'logprob': -20.125}, {'token': '변', 'bytes': [235, 179, 128], 'logprob': -21.0}]}\n",
      "{'token': '시', 'bytes': [236, 139, 156], 'logprob': 0.0, 'top_logprobs': [{'token': '시', 'bytes': [236, 139, 156], 'logprob': 0.0}, {'token': '시장', 'bytes': [236, 139, 156, 236, 158, 165], 'logprob': -16.875}, {'token': '시에', 'bytes': [236, 139, 156, 236, 151, 144], 'logprob': -17.375}, {'token': '市', 'bytes': [229, 184, 130], 'logprob': -20.75}, {'token': '십', 'bytes': [236, 139, 173], 'logprob': -21.0}]}\n",
      "{'token': '(', 'bytes': [40], 'logprob': -0.16051778197288513, 'top_logprobs': [{'token': '(', 'bytes': [40], 'logprob': -0.16051778197288513}, {'token': '입니다', 'bytes': [236, 158, 133, 235, 139, 136, 235, 139, 164], 'logprob': -1.9105178117752075}, {'token': ',', 'bytes': [44], 'logprob': -8.160517692565918}, {'token': ' 입니다', 'bytes': [32, 236, 158, 133, 235, 139, 136, 235, 139, 164], 'logprob': -12.410517692565918}, {'token': '(S', 'bytes': [40, 83], 'logprob': -13.410517692565918}]}\n",
      "{'token': '서울', 'bytes': [236, 132, 156, 236, 154, 184], 'logprob': -0.011895745061337948, 'top_logprobs': [{'token': '서울', 'bytes': [236, 132, 156, 236, 154, 184], 'logprob': -0.011895745061337948}, {'token': 'Se', 'bytes': [83, 101], 'logprob': -4.511895656585693}, {'token': '줄', 'bytes': [236, 164, 132], 'logprob': -7.136895656585693}, {'token': '일', 'bytes': [236, 157, 188], 'logprob': -10.511896133422852}, {'token': '약', 'bytes': [236, 149, 189], 'logprob': -11.136896133422852}]}\n",
      "{'token': ')', 'bytes': [41], 'logprob': -0.0003022153687197715, 'top_logprobs': [{'token': ')', 'bytes': [41], 'logprob': -0.0003022153687197715}, {'token': ',', 'bytes': [44], 'logprob': -8.1253023147583}, {'token': '시', 'bytes': [236, 139, 156], 'logprob': -12.5003023147583}, {'token': ' 또는', 'bytes': [32, 235, 152, 144, 235, 138, 148], 'logprob': -14.1253023147583}, {'token': ';', 'bytes': [59], 'logprob': -14.5003023147583}]}\n",
      "{'token': '입니다', 'bytes': [236, 158, 133, 235, 139, 136, 235, 139, 164], 'logprob': -7.941850526549388e-06, 'top_logprobs': [{'token': '입니다', 'bytes': [236, 158, 133, 235, 139, 136, 235, 139, 164], 'logprob': -7.941850526549388e-06}, {'token': ' 입니다', 'bytes': [32, 236, 158, 133, 235, 139, 136, 235, 139, 164], 'logprob': -11.750007629394531}, {'token': 'です', 'bytes': [227, 129, 167, 227, 129, 153], 'logprob': -18.37500762939453}, {'token': '\\u200b', 'bytes': [226, 128, 139], 'logprob': -19.00000762939453}, {'token': '\\ufeff', 'bytes': [239, 187, 191], 'logprob': -23.50000762939453}]}\n",
      "{'token': '.', 'bytes': [46], 'logprob': -1.771655115589965e-05, 'top_logprobs': [{'token': '.', 'bytes': [46], 'logprob': -1.771655115589965e-05}, {'token': '.\\n\\n', 'bytes': [46, 10, 10], 'logprob': -11.000018119812012}, {'token': '.\\u200b', 'bytes': [46, 226, 128, 139], 'logprob': -14.125018119812012}, {'token': '.\\n', 'bytes': [46, 10], 'logprob': -16.625017166137695}, {'token': '<|end|>', 'bytes': None, 'logprob': -16.875017166137695}]}\n"
     ]
    }
   ],
   "source": [
    "for i in response_metadata[\"logprobs\"]['content']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0836db96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한\t\t 100.0%\n",
      "대한민국\t\t 0.0%\n",
      "네\t\t 0.0%\n",
      "\"\t\t 0.0%\n",
      "대\t\t 0.0%\n",
      "-----\n",
      "민국\t\t 100.0%\n",
      "민\t\t 0.0%\n",
      "미\t\t 0.0%\n",
      "대한민국\t\t 0.0%\n",
      "한국\t\t 0.0%\n",
      "-----\n",
      "의\t\t 99.97%\n",
      "(\t\t 0.03%\n",
      "(K\t\t 0.0%\n",
      "の\t\t 0.0%\n",
      ",\t\t 0.0%\n",
      "-----\n",
      "수도\t\t 100.0%\n",
      "수\t\t 0.0%\n",
      "**\t\t 0.0%\n",
      "\t\t 0.0%\n",
      "공식\t\t 0.0%\n",
      "-----\n",
      "는\t\t 100.0%\n",
      "は\t\t 0.0%\n",
      "은\t\t 0.0%\n",
      "는\t\t 0.0%\n",
      "(\t\t 0.0%\n",
      "-----\n",
      "**\t\t 49.92%\n",
      "서울\t\t 49.92%\n",
      "\"\t\t 0.16%\n",
      "'\t\t 0.01%\n",
      "\"**\t\t 0.0%\n",
      "-----\n",
      "특\t\t 90.36%\n",
      "입니다\t\t 9.52%\n",
      "(\t\t 0.11%\n",
      "특별\t\t 0.01%\n",
      "Special\t\t 0.0%\n",
      "-----\n",
      "별\t\t 100.0%\n",
      "別\t\t 0.0%\n",
      "별\t\t 0.0%\n",
      "别\t\t 0.0%\n",
      "변\t\t 0.0%\n",
      "-----\n",
      "시\t\t 100.0%\n",
      "시장\t\t 0.0%\n",
      "시에\t\t 0.0%\n",
      "市\t\t 0.0%\n",
      "십\t\t 0.0%\n",
      "-----\n",
      "(\t\t 85.17%\n",
      "입니다\t\t 14.8%\n",
      ",\t\t 0.03%\n",
      "입니다\t\t 0.0%\n",
      "(S\t\t 0.0%\n",
      "-----\n",
      "서울\t\t 98.82%\n",
      "Se\t\t 1.1%\n",
      "줄\t\t 0.08%\n",
      "일\t\t 0.0%\n",
      "약\t\t 0.0%\n",
      "-----\n",
      ")\t\t 99.97%\n",
      ",\t\t 0.03%\n",
      "시\t\t 0.0%\n",
      "또는\t\t 0.0%\n",
      ";\t\t 0.0%\n",
      "-----\n",
      "입니다\t\t 100.0%\n",
      "입니다\t\t 0.0%\n",
      "です\t\t 0.0%\n",
      "​\t\t 0.0%\n",
      "﻿\t\t 0.0%\n",
      "-----\n",
      ".\t\t 100.0%\n",
      ".\t\t 0.0%\n",
      ".​\t\t 0.0%\n",
      ".\t\t 0.0%\n",
      "<|end|>\t\t 0.0%\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for token in response_metadata[\"logprobs\"][\"content\"]:\n",
    "    for i in token['top_logprobs']:\n",
    "        token_str = i[\"token\"].strip()\n",
    "        logprob = float(i[\"logprob\"])\n",
    "        print(f\"{token_str}\\t\\t {np.round(np.exp(logprob)*100, 2)}%\")\n",
    "    print(\"-----\")\n",
    "    # top_token_str = token[\"token\"].strip()\n",
    "    # top_logprob = float(token[\"logprob\"])\n",
    "    # print(f\"TOP: {top_token_str}\\t\\t {np.round(np.exp(top_logprob)*100, 2)}%\")\n",
    "\n",
    "# # 출력 확률이 가장 높은 토큰만 출력\n",
    "# for token in response_metadata[\"logprobs\"][\"content\"]:\n",
    "#     top_token_str = token[\"token\"].strip()\n",
    "#     top_logprob = float(token[\"logprob\"])\n",
    "#     print(f\"TOP: {top_token_str}\\t\\t {np.round(np.exp(top_logprob)*100, 2)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "37791993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한\t\t 100.0%\n",
      "민국\t\t 100.0%\n",
      "의\t\t 99.97%\n",
      "수도\t\t 100.0%\n",
      "는\t\t 100.0%\n",
      "서울\t\t 49.92%\n",
      "특\t\t 90.36%\n",
      "별\t\t 100.0%\n",
      "시\t\t 100.0%\n",
      "(\t\t 85.17%\n",
      "서울\t\t 98.82%\n",
      ")\t\t 99.97%\n",
      "입니다\t\t 100.0%\n",
      ".\t\t 100.0%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for token in response_metadata[\"logprobs\"][\"content\"]:\n",
    "    token_str = token[\"token\"].strip()\n",
    "    logprob = float(token[\"logprob\"])\n",
    "    print(f\"{token_str}\\t\\t {np.round(np.exp(logprob)*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aec3e6",
   "metadata": {},
   "source": [
    "### 스트리밍 출력\n",
    "\n",
    "스트리밍은 모델이 생성하는 토큰을 순차적으로 전송해, 응답을 실시간으로 확인할 수 있도록 한다. 긴 답변도 대기 시간을 줄여 빠르게 피드백을 받을 수 있다.\n",
    "\n",
    "#### 장점\n",
    "\n",
    "- **지연 감소**: 부분 결과를 즉시 확인\n",
    "- **과정 노출**: 생성 진행 상황 파악\n",
    "- **UX 향상**: 대화형 애플리케이션에 적합\n",
    "\n",
    "#### 활용 예\n",
    "\n",
    "- **긴 문서 작성 미리보기**\n",
    "- **실시간 챗봇 응답**\n",
    "- **데모/발표 환경**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbc5d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스트리밍 방식으로 LLM에 질의\n",
    "# 실시간으로 토큰이 생성되는 과정을 확인할 수 있음\n",
    "answer = llm.stream(\"대한민국의 아름다운 관광지 10곳과 주소를 알려주세요!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a90e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스트리밍 응답을 실시간으로 출력\n",
    "# 각 토큰이 생성될 때마다 즉시 화면에 표시됨\n",
    "for token in answer:\n",
    "    print(token.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f079b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "# 스트리밍 방식으로 LLM에 질의\n",
    "answer = llm.stream(\"대한민국의 아름다운 관광지 10곳과 주소를 알려주세요!\")\n",
    "\n",
    "# langchain_teddynote의 stream_response 함수로 깔끔하게 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e95ce8b",
   "metadata": {},
   "source": [
    "## 멀티모달 AI - 이미지를 읽는 인공지능\n",
    "\n",
    "**멀티모달(Multimodal)** 은 여러 종류의 데이터를 동시에 처리하는 기술이다. **텍스트, 이미지, 오디오, 비디오** 등 복수 입력을 이해한다.\n",
    "\n",
    "### 처리 가능한 데이터 타입\n",
    "\n",
    "- **텍스트**: 문서, 이메일, 웹페이지 등\n",
    "- **이미지**: 사진, 차트, 표, 스크린샷 등\n",
    "- **오디오**: 음성, 음악, 효과음 등\n",
    "- **비디오**: 동영상, 애니메이션 등\n",
    "\n",
    "### GPT-4.1 의 비전(Vision) 기능\n",
    "\n",
    "**GPT-4.1** 은 강력한 **이미지 인식 능력** 을 갖춘 멀티모달 모델이다.\n",
    "\n",
    "#### 이미지 분석 작업 예\n",
    "\n",
    "- **차트/그래프 해석**: 데이터 시각화 분석\n",
    "- **문서 OCR**: 이미지 속 텍스트 추출 및 해석\n",
    "- **장면 설명**: 사진 속 상황과 객체 인식\n",
    "- **표/양식 처리**: 복잡한 테이블 데이터 이해\n",
    "- **시각 자료 분석**: 그림, 디자인 요소 해석\n",
    "\n",
    "#### 비즈니스 활용 예\n",
    "\n",
    "- **재무제표 분석**: 복잡한 회계 자료 자동 해석\n",
    "- **의료 영상 검토**: X-ray, MRI 이미지 보조 분석\n",
    "- **건축 도면 검토**: 설계도 및 시공 현황 파악\n",
    "- **제품 관리**: 상품 사진을 통한 품질 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a859058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.models import MultiModal\n",
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "# 기본 ChatOpenAI 객체 생성\n",
    "import os\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성\n",
    "    model_name=\"openai/gpt-4.1\",  # 이미지 인식이 가능한 모델 (OpenRouter)\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),  # OpenRouter API 키\n",
    "    base_url=os.getenv(\"OPENROUTER_BASE_URL\"),  # OpenRouter API URL\n",
    ")\n",
    "\n",
    "# 멀티모달(이미지 + 텍스트 처리) 객체 생성\n",
    "multimodal_llm = MultiModal(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c16ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹상의 이미지 URL 정의\n",
    "IMAGE_URL = \"https://t3.ftcdn.net/jpg/03/77/33/96/360_F_377339633_Rtv9I77sSmSNcev8bEcnVxTHrXB4nRJ5.jpg\"\n",
    "\n",
    "# 웹 이미지를 직접 분석하여 스트리밍 응답 생성\n",
    "answer = multimodal_llm.stream(IMAGE_URL)\n",
    "\n",
    "# 실시간으로 이미지 분석 결과 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006ec2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로컬 저장된 이미지 파일 경로 정의\n",
    "IMAGE_PATH_FROM_FILE = \"01-LCEL/images/sample-image.png\"\n",
    "\n",
    "# 로컬 이미지 파일을 분석하여 스트리밍 응답 생성\n",
    "answer = multimodal_llm.stream(IMAGE_PATH_FROM_FILE)\n",
    "\n",
    "# 실시간으로 이미지 분석 결과 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be092af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시스템 프롬프트: AI의 역할과 행동 방식을 정의\n",
    "system_prompt = \"\"\"You are a professional financial AI assistant specialized in analyzing financial statements and tables. \n",
    "Your mission is to interpret given tabular financial data and provide insightful, interesting findings in a friendly and helpful manner. \n",
    "Focus on key metrics, trends, and notable patterns that would be valuable for business analysis.\n",
    "\n",
    "[IMPORTANT]\n",
    "- 한글로 답변해 주세요.\n",
    "\"\"\"\n",
    "\n",
    "# 사용자 프롬프트: 구체적인 작업 지시사항\n",
    "user_prompt = \"\"\"Please analyze the financial statement provided in the image. \n",
    "Identify and summarize the most interesting and important findings, including key financial metrics, trends, and insights that would be valuable for business decision-making.\"\"\"\n",
    "\n",
    "# 커스텀 프롬프트가 적용된 멀티모달 객체 생성\n",
    "multimodal_llm_with_prompt = MultiModal(\n",
    "    llm,\n",
    "    system_prompt=system_prompt,  # 시스템 역할 정의\n",
    "    user_prompt=user_prompt,  # 사용자 요청 정의\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51735d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석할 재무제표 이미지 URL\n",
    "IMAGE_PATH_FROM_FILE = \"https://storage.googleapis.com/static.fastcampus.co.kr/prod/uploads/202212/080345-661/kwon-01.png\"\n",
    "\n",
    "# 커스텀 프롬프트가 적용된 멀티모달 LLM으로 재무제표 분석\n",
    "answer = multimodal_llm_with_prompt.stream(IMAGE_PATH_FROM_FILE)\n",
    "\n",
    "# 재무제표 분석 결과를 실시간으로 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4e4b14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
